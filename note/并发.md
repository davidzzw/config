### 线程

###特性

- `可见性`：`一个线程对主内存的修改可以及时的被其他线程观察到`
- `有序性`：`一个线程观察其他线程中的指令执行顺序，由于指令 重排序的存在，该观察结果一般杂乱无序`
- `原子性`：`提供了互斥访问`

#####8种原子操作

- `lock（锁定）`：`作用于主内存的变量，它把一个变量标识为一条线程独占的状态`
- `unlock（解锁）`：`作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定`
- `read（读取）`：`作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的 load 动作使用`
- `load（载入）`：`作用于工作内存的变量，它把 read 操作从主内存中得到的变量值放入工作内存的变量副本中`
- `use（使用）`：`作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作`
- `assign（赋值）`：`作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作`
- `store（存储）`：`作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的 write 操作使用`
- `write（写入）`：`作用于主内存的变量，它把 store 操作从工作内存中得到的变量的值放入主内存的变量中`

#### 状态

#####NEW（新建）

#####RUNNABLE（可运行）

#####BLOCKED（阻塞）

#####WAITING（无限期等待）

* `没有设置timeout参数的Object.wait()`
* `没有设置timeout参数的Thread.join()`
* `LockSupport.park()`

#####TIMED_WAITING（限期等待）

* `Thread.sleep()`
* `设置了timeout参数的Object.wait()`
* `设置了timeout参数的Thread.join()`
* `LockSupport.parkNanos()`
* `LockSupport.parkUntil()`

#### TERMINATED（结束）

![线程状态转换图](D:\config\pic\线程状态转换图.jpg)

### Happen-before

```
1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 
2. 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法
```

####happens-before原则规则

* `程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作`
* `锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作`
* `volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作`
* `传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C`
* `线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作`
* `线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生`
* `线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束Thread.isAlive()的返回值手段检测到线程已经终止执行`
* `对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始`

**程序次序规则**：`一段代码在单线程中执行的结果是有序的。注意是执行结果，因为虚拟机、处理器会对指令进行重排序（重排序后面会详细介绍）。虽然重排序了，但是并不会影响程序的执行结果，所以程序最终执行的结果与顺序执行的结果是一致的。故而这个规则只对单线程有效，在多线程环境下无法保证正确性`

**锁定规则**：`这个规则比较好理解，无论是在单线程环境还是多线程环境，一个锁处于被锁定状态，那么必须先执行unlock操作后面才能进行lock操作`

**volatile变量规则**：`这是一条比较重要的规则，它标志着volatile保证了线程可见性。通俗点讲就是如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作一定是happens-before读操作的`

**传递规则**：`提现了happens-before原则具有传递性，即A happens-before B , B happens-before C，那么A happens-before C`

**线程启动规则**：`假定线程A在执行过程中，通过执行ThreadB.start()来启动线程B，那么线程A对共享变量的修改在接下来线程B开始执行后确保对线程B可见`

**线程终结规则**：`假定线程A在执行的过程中，通过制定ThreadB.join()等待线程B终止，那么线程B在终止之前对共享变量的修改在线程A等待返回后可见`

上面八条是原生Java满足Happens-before关系的规则，但是我们可以对他们进行推导出其他满足happens-before的规则：

* `将一个元素放入一个线程安全的队列的操作Happens-Before从队列中取出这个元素的操作`
* `将一个元素放入一个线程安全容器的操作Happens-Before从容器中取出这个元素的操作`
* `在CountDownLatch上的倒数操作Happens-Before CountDownLatch#await()操作`
* `释放Semaphore许可的操作Happens-Before获得许可操作`
* `Future表示的任务的所有操作Happens-Before Future#get()操作`
* `向Executor提交一个Runnable或Callable的操作Happens-Before任务开始执行操作`

这里再说一遍happens-before的概念：**如果两个操作不存在上述（前面8条 + 后面6条）任一一个happens-before规则，那么这两个操作就没有顺序的保障，JVM可以对这两个操作进行重排序。如果操作A happens-before操作B，那么操作A在内存上所做的操作对操作B都是可见的**

### 重排序

#### 编译器重排序

`编译器在不改变单线程语义的前提下，为了提高程序的运行速度，可以对字节码指令进行重新排序，所以代码中a、b的赋值顺序，被编译之后可能就变成了先设置b，再设置a`

####CPU指令重排序

```
在MESI协议中，每个Cache line有4种状态，分别是：
1、M(Modified) 这行数据有效，但是被修改了，和内存中的数据不一致，数据只存在于本Cache中
2、E(Exclusive) 这行数据有效，和内存中的数据一致，数据只存在于本Cache中
3、S(Shared) 这行数据有效，和内存中的数据一致，数据分布在很多Cache中
4、I(Invalid) 这行数据无效
每个Core的Cache控制器不仅知道自己的读写操作，也监听其它Cache的读写操作，假如有4个Core： 
1、Core1从内存中加载了变量X，值为10，这时Core1中缓存变量X的cache line的状态是E； 
2、Core2也从内存中加载了变量X，这时Core1和Core2缓存变量X的cache line状态转化成S； 
3、Core3也从内存中加载了变量X，然后把X设置成了20，这时Core3中缓存变量X的cache line状态转化成M，其它Core对应的cache line变成I（无效）
当然了，不同的处理器内部细节也是不一样的，比如Intel的core i7处理器使用从MESI中演化出的MESIF协议，F(Forward)从Share中演化而来，一个cache line如果是F状态，可以把数据直接传给其它内核，这里就不纠结了。
```

**CPU在cache line状态的转化期间是阻塞的，经过长时间的优化，在寄存器和L1缓存之间添加了LoadBuffer、StoreBuffer来降低阻塞时间，Buffer与L1进行数据传输时，CPU无须等待。**

**1、CPU执行load读数据时，把读请求放到LoadBuffer，这样就不用等待其它CPU响应，先进行下面操作，稍后再处理这个读请求的结果。**
**2、CPU执行store写数据时，把数据写到StoreBuffer中，待到某个适合的时间点，把StoreBuffer的数据刷到主存中。**
**因为StoreBuffer的存在，CPU在写数据时，真实数据并不会立即表现到内存中，所以对于其它CPU是不可见的；同样的道理，LoadBuffer中的请求也无法拿到其它CPU设置的最新数据；**
**由于StoreBuffer和LoadBuffer是异步执行的，所以在外面看来，先写后读，还是先读后写，没有严格的固定顺序。**

###内存屏障

**从CPU缓存结构分析中已经知道：一个load操作需要进入LoadBuffer，然后再去内存加载；一个store操作需要进入StoreBuffer，然后再写入缓存，这两个操作都是异步的，会导致不正确的指令重排序，所以在JVM中定义了一系列的内存屏障来指定指令的执行顺序。**

* `loadload屏障（load1，loadload， load2）` 
* `loadstore屏障（load，loadstore， store）`
* `storestore屏障（store1，storestore， store2）`
* `storeload屏障（store，storeload， load）`

###synchronized

###volatile

###AbstractQueuedSynchronizer

###CAS

```
CAS（compare and swap）的缩写，中文翻译成比较并交换。
CAS 不通过JVM,直接利用java本地方 JNI（Java Native Interface为JAVA本地调用）,直接调用CPU 的cmpxchg（是汇编指令）指令。
利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法,实现原子操作。其它原子操作都是利用类似的特性完成的。整个java.util.concurrent都是建立在CAS之上的，因此对于synchronized阻塞算法，J.U.C在性能上有了很大的提升。
CAS是项乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。
```

####CAS应用

`CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做`

####CAS优点

`确保对内存的读-改-写操作都是原子操作执行`

####CAS缺点

`CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。ABA问题，循环时间长开销大和只能保证一个共享变量的原子操作`

####总结

1. **使用CAS在线程冲突严重时，会大幅降低程序性能；CAS只适合于线程冲突较少的情况使用**。
2. **synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS**

### 死锁

#### 饥饿 丢失信号 活锁

#### 无饥饿

#### 无障碍

#### 无等待

- 有界无等待
- 线程数无关
